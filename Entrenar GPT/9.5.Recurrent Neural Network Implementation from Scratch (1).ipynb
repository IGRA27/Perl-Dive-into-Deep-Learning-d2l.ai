{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f79ae41",
   "metadata": {},
   "source": [
    "# Isaac Reyes, Alejandro Moya, José Guzmán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68347982",
   "metadata": {},
   "source": [
    "## 9.5. Implementación de Red Neuronal Recurrente desde Cero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb4037",
   "metadata": {},
   "source": [
    "Ahora estamos preparados para implementar una RNR desde cero. En particular, entrenaremos esta RNR para que funcione como un modelo de lenguaje a nivel de caracteres (ver <u>Sección 9.4</u>) y la entrenaremos con un corpus que consiste en el texto completo de La Máquina del Tiempo de H. G. Wells, siguiendo los pasos de procesamiento de datos descritos en <u>Sección 9.2</u>. Comenzamos cargando el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f7663",
   "metadata": {},
   "source": [
    "### imp y conf inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77ffdf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "use strict;\n",
    "use warnings;\n",
    "use Data::Dump qw(dump);\n",
    "use AI::MXNet qw(mx);\n",
    "use d2l;\n",
    "IPerl->load_plugin('Chart::Plotly');\n",
    "use List::Util qw(sum);\n",
    "use jjap::numperl;\n",
    "use constant np => 'numperl';\n",
    "use experimental 'smartmatch';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff295bec",
   "metadata": {},
   "source": [
    "## 9.5.1. Modelo RNN\n",
    "\n",
    "Iniciamos definiendo una clase para implementar el modelo RNN (<u>Sección 9.4.2</u>). Es importante notar que el número de unidades ocultas num_hiddens es un hiperparámetro ajustable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ceb792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine new redefined at reply input line 4.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine new redefined at reply input line 4.\n"
     ]
    }
   ],
   "source": [
    "package RNNScratch{\n",
    "    use base qw(d2l::Module); #@save\n",
    "    #The RNN model implemented from scratch.\n",
    "    sub new{\n",
    "        my ($class, %args) = (shift, d2l->get_arguments(num_inputs=>0, num_hiddens=>0, sigma=>0.01, \\@_));\n",
    "        my $self = $class->SUPER::new();\n",
    "        $self->save_hyperparameters(%args);\n",
    "\n",
    "        $self->{W_xh} = mx->nd->random->randn($args{num_inputs}, $args{num_hiddens}) * $args{sigma};\n",
    "        $self->{W_hh} = mx->nd->random->randn($args{num_hiddens}, $args{num_hiddens}) * $args{sigma};\n",
    "        $self->{b_h} = mx->nd->zeros([$args{num_hiddens}]);\n",
    "        return bless($self, $class);\n",
    "    }\n",
    "    1;    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6992b",
   "metadata": {},
   "source": [
    "El método forward a continuación define cómo calcular la salida y el estado oculto en cualquier momento, dado la entrada actual y el estado del modelo en el paso de tiempo anterior. Note que el modelo RNN recorre la dimensión más externa de inputs, actualizando el estado oculto paso a paso. El modelo aquí utiliza una función de activación $\\tanh$ (<u>Sección 5.1.2.3</u>).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1b2d4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*RNNScratch::forward"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine RNNScratch::forward redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine RNNScratch::forward redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n"
     ]
    }
   ],
   "source": [
    "my $forward = sub{\n",
    "    my ($self, %args) = (shift, d2l->get_arguments(inputs => undef,\n",
    "                                                    state => undef,\\@_));\n",
    "                            \n",
    "    if (!defined $args{state}){\n",
    "        # Initial state with shape: (batch_size, num_hiddens)\n",
    "        $args{state} = mx->nd->zeros([$args{inputs}->shape->[1], $self->{num_hiddens}], ctx => $args{inputs}->context );\n",
    "    }else{\n",
    "        ($args{state}, undef) = @{$args{state}};        \n",
    "    }\n",
    "    my $outputs;\n",
    "    my $first_dot;\n",
    "    my $second_dot;\n",
    "    my $total;\n",
    "    foreach my $X (@{$args{inputs}}){ # Shape of inputs: (num_steps, batch_size, num_inputs)\n",
    "        $first_dot = mx->nd->dot($X, $self->{W_xh});\n",
    "        $second_dot = mx->nd->dot($args{state}, $self->{W_hh});\n",
    "        $total = $first_dot + $second_dot + $self->{b_h};\n",
    "        $args{state} = mx->nd->tanh($total);\n",
    "        push @$outputs, $args{state};\n",
    "\n",
    "    }\n",
    "    \n",
    "    return $outputs, $args{state};\n",
    "    \n",
    "};\n",
    "d2l->add_to_class('RNNScratch', 'forward', $forward);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f9ed6",
   "metadata": {},
   "source": [
    "Podemos introducir un minibatch de secuencias de entrada en un modelo RNN de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8d617b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARRAY(0xbf29178)<AI::MXNet::NDArray 2x32 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my ($batch_size, $num_inputs, $num_hiddens, $num_steps) = (2, 16, 32, 100);\n",
    "my $rnn = RNNScratch->new(num_inputs => $num_inputs, \n",
    "                            num_hiddens => $num_hiddens);\n",
    "my $X = mx->nd->ones([$num_steps, $batch_size, $num_inputs]);\n",
    "my ($outputs, $state) = $rnn->forward($X);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b8a6e",
   "metadata": {},
   "source": [
    "Vamos a verificar si el modelo RNN produce resultados con las dimensiones correctas para asegurarnos de que la dimensionalidad del estado oculto permanezca sin cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52a9d52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine check_len redefined at reply input line 1.\n\nSubroutine check_shape redefined at reply input line 17.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine check_len redefined at reply input line 1.\n\nSubroutine check_shape redefined at reply input line 17.\n"
     ]
    }
   ],
   "source": [
    "sub check_len{ #@save\n",
    "    my ($a, $n) = @_;\n",
    "    #Check the length of a list.\n",
    "    if (ref ($a) eq 'AI::MXNet::NDArray'){\n",
    "        if($a->len != $n){\n",
    "        print STDERR \" list's length \", $a->len, \" != expected length \", $n;\n",
    "        }\n",
    "    }\n",
    "    if (ref($a) eq 'ARRAY'){\n",
    "        if(scalar @$a != $n){\n",
    "            print STDERR \" list's length \", scalar @$a, \" != expected length \", $n;\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "sub check_shape{ #@save\n",
    "    my ($a, $shape) = @_;\n",
    "    #Check the shape of a tensor.\n",
    "    print STDERR \"tensor's shape\", dump ($a->shape), \" != expected shape \", dump ($shape) unless (@{$a->shape} ~~ @{$shape});\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "check_len($outputs, $num_steps);\n",
    "check_shape($outputs->[0], [$batch_size, $num_hiddens]);\n",
    "check_shape($state, [$batch_size, $num_hiddens]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3d3ed",
   "metadata": {},
   "source": [
    "## 9.5.2. Modelo de Lenguaje Basado en RNN\n",
    "\n",
    "\n",
    "La clase RNNLMScratch que se presenta a continuación define un modelo de lenguaje basado en RNN, donde pasamos nuestro RNN a través del argumento rnn del método __init__. Al entrenar modelos de lenguaje, las entradas y salidas provienen del mismo vocabulario. Por lo tanto, tienen la misma dimensión, que es igual al tamaño del vocabulario. Note que usamos la perplejidad para evaluar el modelo. Como se discutió en la <u>Sección 9.3.2</u>, esto asegura que secuencias de diferentes longitudes sean comparables.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10279f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine new redefined at reply input line 7.\n\nSubroutine init_params redefined at reply input line 16.\n\nSubroutine training_step redefined at reply input line 27.\n\nSubroutine validation_step redefined at reply input line 34.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine new redefined at reply input line 7.\n\nSubroutine init_params redefined at reply input line 16.\n\nSubroutine training_step redefined at reply input line 27.\n\nSubroutine validation_step redefined at reply input line 34.\n"
     ]
    }
   ],
   "source": [
    "package RNNLMScratch{\n",
    "    use base qw(d2l::Classifier); #@save\n",
    "    use Data::Dump qw(dump);    \n",
    "    use jjap::numperl;\n",
    "    use constant np => 'numperl';\n",
    "    #The RNN-based language model implemented from scratch.\n",
    "sub new{\n",
    "        my ($class, %args) = (shift, d2l->get_arguments(rnn=>undef, vocab_size=>0, lr=>0.01, \\@_));\n",
    "\n",
    "\n",
    "        my $self = $class->SUPER::new();\n",
    "        $self->save_hyperparameters(%args);\n",
    "        $self->init_params();\n",
    "        return bless($self, $class);\n",
    "    }\n",
    "    sub init_params{\n",
    "        my $self = shift;\n",
    "        \n",
    "        $self->{W_hq} = mx->nd->random->randn(\n",
    "        $self->{rnn}->{num_hiddens}, $self->{vocab_size}) * $self->{rnn}->{sigma};\n",
    "        $self->{b_q} = mx->nd->zeros([$self->{vocab_size}]);\n",
    "        \n",
    "        for my $param (@{$self->get_scratch_params()}){\n",
    "            $param->attach_grad();\n",
    "        }       \n",
    "    }\n",
    "    sub training_step{\n",
    "        my ($self, $batch) = @_; #batch es un array\n",
    "        my $l = $self->loss($self->forward(@$batch[0 .. scalar(@$batch) - 2]), @$batch[1]);\n",
    "        $self->plot('ppl', mx->nd->array(np->exp($l->asarray)->asarray), train => 1);\n",
    "        return $l;\n",
    "    }\n",
    "\n",
    "    sub validation_step{\n",
    "        my ($self, $batch) = @_;\n",
    "        my $l = $self->loss($self->forward(@$batch[0 .. scalar(@$batch) - 2]), @$batch[1]);\n",
    "        $self->plot('ppl', mx->nd->array(np->exp($l->asarray)->asarray), train => 0);\n",
    "    }\n",
    "        \n",
    "    \n",
    "    1;    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18579ee3",
   "metadata": {},
   "source": [
    "### 9.5.2.1. Codificación One-Hot\n",
    "\n",
    "Recuerda que cada token se representa \n",
    "por un índice numérico que indica la\n",
    "posición en el vocabulario de la \n",
    "palabra/carácter/pieza de palabra correspondiente.\n",
    "Podrías pensar en construir una red neuronal\n",
    "con un solo nodo de entrada (en cada paso de tiempo),\n",
    "donde el índice se podría introducir como un valor escalar.\n",
    "Esto funciona cuando tratamos con entradas numéricas \n",
    "como el precio o la temperatura, donde dos valores \n",
    "suficientemente cercanos\n",
    "deben ser tratados de manera similar.\n",
    "Pero esto no tiene mucho sentido. \n",
    "Las palabras $45^{\\text{a}}$ y $46^{\\text{a}}$ \n",
    "en nuestro vocabulario resultan ser \"their\" y \"said\",\n",
    "cuyos significados no son para nada similares.\n",
    "\n",
    "Cuando tratamos con datos categóricos,\n",
    "la estrategia más común es representar\n",
    "cada elemento mediante una *codificación one-hot*\n",
    "(recuerda la <u>Sección 4.1.1</u>). Una codificación one-hot es un vector cuya longitud es dada por el tamaño del vocabulario  N , donde todas las entradas se establecen en  0 , excepto la entrada correspondiente a nuestro token, que se establece en  1 . Por ejemplo, si el vocabulario tuviera cinco elementos, entonces los vectores one-hot correspondientes a los índices 0 y 2 serían los siguientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a978e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[\n",
       " [1 0 0 0 0]\n",
       " [0 0 1 0 0]\n",
       "]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx->nd->one_hot(mx->nd->array([0,2]),5)->aspdl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78365c54",
   "metadata": {},
   "source": [
    "Los minibatches que muestreamos en cada iteración\n",
    "tomarán la forma (tamaño del lote, número de pasos de tiempo).\n",
    "Una vez que representamos cada entrada como un vector one-hot,\n",
    "podemos pensar en cada minibatch como un tensor tridimensional,\n",
    "donde la longitud a lo largo del tercer eje\n",
    "está dada por el tamaño del vocabulario (`len(vocab)`).\n",
    "A menudo transponemos la entrada para que obtengamos una salida\n",
    "de forma (número de pasos de tiempo, tamaño del lote, tamaño del vocabulario).\n",
    "Esto nos permitirá recorrer más convenientemente la dimensión más externa\n",
    "para actualizar los estados ocultos de un minibatch,\n",
    "paso a paso en el tiempo\n",
    "(por ejemplo, en el método `forward` mencionado anteriormente).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ad23107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*RNNLMScratch::one_hot"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine RNNLMScratch::one_hot redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine RNNLMScratch::one_hot redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n"
     ]
    }
   ],
   "source": [
    "my $one_hot = sub {\n",
    "my ($self, $X) = @_;\n",
    "    # Output shape: (num_steps, batch_size, vocab_size)\n",
    "    return mx->nd->one_hot($X->transpose, $self->{vocab_size});\n",
    "};\n",
    "d2l->add_to_class('RNNLMScratch', 'one_hot', $one_hot);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c44b8",
   "metadata": {},
   "source": [
    "### 9.5.2.2. Transformando las Salidas de RNN\n",
    "\n",
    "El modelo de lenguaje utiliza una capa de salida completamente conectada\n",
    "para transformar las salidas de RNN en predicciones de tokens en cada paso de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c87201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*RNNLMScratch::output_layer"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine RNNLMScratch::output_layer redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine RNNLMScratch::output_layer redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n"
     ]
    }
   ],
   "source": [
    "my $output_layer = sub{\n",
    "    my ($self, $rnn_outputs) = @_;\n",
    "    my @outputs;\n",
    "    foreach my $H (@$rnn_outputs){\n",
    "        push (@outputs, (mx->nd->dot($H, $self->{W_hq}) + $self->{b_q}));\n",
    "    }\n",
    "    return mx->nd->stack(@outputs, axis => 1);\n",
    "};\n",
    "d2l->add_to_class('RNNLMScratch', 'output_layer', $output_layer); #@save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c1ae871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*RNNLMScratch::forward"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine RNNLMScratch::forward redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine RNNLMScratch::forward redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n"
     ]
    }
   ],
   "source": [
    "my $forward = sub{\n",
    "    my ($self, $X, $state) = @_;\n",
    "    my $embs = $self->one_hot($X);\n",
    "    (my $rnn_outputs, $state) = $self->{rnn}->forward($embs, $state);\n",
    "    return $self->output_layer($rnn_outputs);\n",
    "    \n",
    "};\n",
    "d2l->add_to_class('RNNLMScratch', 'forward', $forward); #@save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c4dd1",
   "metadata": {},
   "source": [
    "Verifiquemos si el cálculo hacia adelante\n",
    "produce salidas con la forma correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a37ceeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $model = RNNLMScratch->new(rnn => $rnn, vocab_size => $num_inputs);\n",
    "my $outputs = $model->forward(mx->nd->ones([$batch_size, $num_steps], dtype => 'int64')); \n",
    "check_shape($outputs, [$batch_size, $num_steps, $num_inputs]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431c6cc",
   "metadata": {},
   "source": [
    "## 9.5.3 Recorte de Gradientes\n",
    "\n",
    "Aunque ya estás acostumbrado a pensar en las redes neuronales\n",
    "como \"profundas\" en el sentido de que muchas capas\n",
    "separan la entrada y salida \n",
    "incluso dentro de un solo paso de tiempo,\n",
    "la longitud de la secuencia introduce\n",
    "una nueva noción de profundidad.\n",
    "Además de pasar por la red\n",
    "en la dirección de entrada a salida,\n",
    "las entradas en el primer paso de tiempo\n",
    "deben pasar por una cadena de \\(T\\) capas\n",
    "a lo largo de los pasos de tiempo para \n",
    "influir en la salida del modelo\n",
    "en el último paso de tiempo.\n",
    "Tomando la perspectiva hacia atrás, en cada iteración,\n",
    "retropropagamos gradientes a través del tiempo,\n",
    "resultando en una cadena de productos matriciales\n",
    "de longitud \\(\\mathcal{O}(T)\\).\n",
    "Como se mencionó en la <u>Sección 5.4</u>, \n",
    "esto puede resultar en inestabilidad numérica,\n",
    "causando que los gradientes exploten o desaparezcan,\n",
    "dependiendo de las propiedades de las matrices de pesos.\n",
    "\n",
    "Lidiar con gradientes que desaparecen y explotan\n",
    "es un problema fundamental al diseñar RNNs\n",
    "y ha inspirado algunos de los mayores avances\n",
    "en arquitecturas modernas de redes neuronales.\n",
    "En el próximo capítulo, hablaremos sobre\n",
    "arquitecturas especializadas que fueron diseñadas\n",
    "con la esperanza de mitigar el problema del gradiente que desaparece.\n",
    "Sin embargo, incluso los RNNs modernos a menudo sufren\n",
    "de gradientes que explotan.\n",
    "Una solución común pero poco elegante\n",
    "es simplemente recortar los gradientes,\n",
    "forzando a los \"recortados\" a tomar valores más pequeños.\n",
    "\n",
    "\n",
    "Generalmente, al optimizar algún objetivo\n",
    "por descenso de gradiente, actualizamos iterativamente\n",
    "el parámetro de interés, digamos un vector \\(\\mathbf{x}\\),\n",
    "empujándolo en la dirección del \n",
    "gradiente negativo \\(\\mathbf{g}\\)\n",
    "(en descenso de gradiente estocástico,\n",
    "calculamos este gradiente\n",
    "en un minibatch muestreado aleatoriamente).\n",
    "Por ejemplo, con una tasa de aprendizaje \\(\\eta > 0\\),\n",
    "cada actualización toma la forma \n",
    "\\(\\mathbf{x} \\gets \\mathbf{x} - \\eta \\mathbf{g}\\).\n",
    "Supongamos además que la función objetivo \\(f\\)\n",
    "es suficientemente suave.\n",
    "Formalmente, decimos que el objetivo\n",
    "es *continuo de Lipschitz* con constante \\(L\\),\n",
    "lo que significa que para cualquier \\(\\mathbf{x}\\) y \\(\\mathbf{y}\\), tenemos\n",
    "\n",
    "$$|f(\\mathbf{x}) - f(\\mathbf{y})| \\leq L \\|\\mathbf{x} - \\mathbf{y}\\|.$$\n",
    "\n",
    "Como puedes ver, cuando actualizamos el vector de parámetros restando \\(\\eta \\mathbf{g}\\),\n",
    "el cambio en el valor del objetivo\n",
    "depende de la tasa de aprendizaje,\n",
    "la norma del gradiente y \\(L\\) de la siguiente manera:\n",
    "\n",
    "$$|f(\\mathbf{x}) - f(\\mathbf{x} - \\eta\\mathbf{g})| \\leq L \\eta\\|\\mathbf{g}\\|.$$\n",
    "\n",
    "En otras palabras, el objetivo no puede\n",
    "cambiar más de \\(L \\eta \\|\\mathbf{g}\\|\\). \n",
    "Tener un valor pequeño para este límite superior\n",
    "podría ser visto como bueno o malo.\n",
    "Por un lado, estamos limitando la velocidad\n",
    "a la que podemos reducir el valor del objetivo.\n",
    "Por otro lado, esto limita cuánto\n",
    "podemos equivocarnos en un solo paso de gradiente.\n",
    "\n",
    "\n",
    "Cuando decimos que los gradientes explotan,\n",
    "nos referimos a que \\(\\|\\mathbf{g}\\|\\) \n",
    "se vuelve excesivamente grande.\n",
    "En el peor de los casos, podríamos hacer tanto\n",
    "daño en un solo paso de gradiente que podríamos\n",
    "deshacer todo el progreso realizado durante\n",
    "miles de iteraciones de entrenamiento.\n",
    "Cuando los gradientes pueden ser tan grandes,\n",
    "el entrenamiento de redes neuronales a menudo diverge,\n",
    "sin lograr reducir el valor del objetivo.\n",
    "Otras veces, el entrenamiento eventualmente converge\n",
    "pero es inestable debido a picos masivos en la pérdida.\n",
    "\n",
    "\n",
    "Una forma de limitar el tamaño de \\(L \\eta \\|\\mathbf{g}\\|\\) \n",
    "es reducir la tasa de aprendizaje \\(\\eta\\) a valores muy pequeños.\n",
    "Esto tiene la ventaja de que no sesgamos las actualizaciones.\n",
    "Pero ¿y si solo *raramente* obtenemos grandes gradientes?\n",
    "Este drástico movimiento ralentiza nuestro progreso en todos los pasos,\n",
    "solo para lidiar con los raros eventos de explosión de gradientes.\n",
    "Una alternativa popular es adoptar una heurística de *recorte de gradientes*\n",
    "proyectando los gradientes \\(\\mathbf{g}\\) sobre una bola\n",
    "de algún radio dado \\(\\theta\\) de la siguiente manera:\n",
    "\n",
    "**$$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}.$$**\n",
    "\n",
    "Esto garantiza que la norma del gradiente nunca exceda \\(\\theta\\)\n",
    "y que el gradiente actualizado esté completamente alineado\n",
    "con la dirección original de \\(\\mathbf{g}\\).\n",
    "También tiene el efecto secundario deseable\n",
    "de limitar la influencia que cualquier minibatch dado\n",
    "(y dentro de él cualquier muestra dada)\n",
    "puede ejercer sobre el vector de parámetros.\n",
    "Esto otorga cierto grado de robustez al modelo.\n",
    "Para ser claros, es un truco.\n",
    "El recorte de gradientes significa que no siempre\n",
    "estamos siguiendo el verdadero gradiente y es difícil\n",
    "razonar analíticamente sobre los posibles efectos secundarios.\n",
    "Sin embargo, es un truco muy útil,\n",
    "y es ampliamente adoptado en implementaciones de RNN\n",
    "en la mayoría de los frameworks de aprendizaje profundo.\n",
    "\n",
    "\n",
    "A continuación, definimos un método para recortar gradientes,\n",
    "que es invocado por el método `fit_epoch` de\n",
    "la clase `d2l.Trainer` (ver <u>Sección 3.4</u>).\n",
    "Nota que al calcular la norma del gradiente,\n",
    "estamos concatenando todos los parámetros del modelo,\n",
    "tratándolos como un único vector de parámetros gigante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d91350ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*d2l::Trainer::clip_gradients"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine d2l::Trainer::clip_gradients redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine d2l::Trainer::clip_gradients redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n"
     ]
    }
   ],
   "source": [
    "my $clip_gradients = sub{\n",
    "my ($self, $grad_clip_val, $model) = @_;\n",
    "    my $params = $model->parameters();    \n",
    "    if (ref $params ne 'ARRAY') {\n",
    "        $params = map { $_->data() } values %{$params};\n",
    "    }\n",
    "\n",
    "    my $norm = 0;\n",
    "    foreach my $param (@$params) {\n",
    "        $norm += ($param->grad() ** 2)->sum();\n",
    "    }\n",
    "    $norm = sqrt($norm);\n",
    "\n",
    "    if ($norm > $grad_clip_val) {\n",
    "        foreach my $param (@$params) {\n",
    "            $param->grad()->[':'] *= $grad_clip_val / $norm;\n",
    "        }\n",
    "    }\n",
    "};\n",
    "d2l->add_to_class('d2l::Trainer', 'clip_gradients', $clip_gradients);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82f256",
   "metadata": {},
   "source": [
    "## 9.5.4. Entrenamiento\n",
    "\n",
    "Usando el conjunto de datos de *La Máquina del Tiempo* (`data`),\n",
    "entrenamos un modelo de lenguaje a nivel de caracteres (`model`)\n",
    "basado en el RNN (`rnn`) implementado desde cero.\n",
    "Ten en cuenta que primero calculamos los gradientes,\n",
    "luego los recortamos y finalmente \n",
    "actualizamos los parámetros del modelo\n",
    "usando los gradientes recortados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "551e395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 21:14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU support.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>\n",
       "//# sourceURL=iperl-devel-plugin-chart-plotly.js\n",
       "            $('#Plotly').each(function(i, e) { $(e).attr('id', 'plotly') });\n",
       "\n",
       "            if (!window.Plotly) {\n",
       "                requirejs.config({\n",
       "                  paths: {\n",
       "                    plotly: ['https://cdn.plot.ly/plotly-latest.min']},\n",
       "                });\n",
       "                window.Plotly = {\n",
       "react : function (div, data, layout, config){\n",
       "                    require(['plotly'], function(plotly) {\n",
       "                      window.Plotly=plotly;\n",
       "Plotly.react(div, data, layout, config);                    });\n",
       "                  }\n",
       "                }\n",
       "            }\n",
       "</script>\n",
       "<div id=\"e4eea3a8-97ad-11ee-b56d-8230e5902f95\"></div>\n",
       "\n",
       "<script>\n",
       "Plotly.react(document.getElementById('e4eea3a8-97ad-11ee-b56d-8230e5902f95'),[{\"y\":[25.9836315155029,22.4022491455078,20.5402694702148,19.4886775970459,18.845389175415,18.3301231384277,17.9427726745605,17.5932205200195,17.3853916168213,17.1529933929443,16.9899635314941,16.8184776306152,16.5814571380615,16.3141967773437,16.0454015731812,15.7161346435547,16.5334995269775,15.4041130065918,15.0342399597168,14.7631242752075,14.837783241272,14.1617553710938,13.8516513824463,13.8053266525269,13.2251123428345,12.8923376083374,12.8374757766724,12.4208517074585,12.1133211135864,12.0150896072388,11.7297872543335,11.560276222229,11.4112949371338,11.2304611206055,11.0382099151611,10.9902599334717,10.8677089691162,10.7229461669922,10.6644010543823,10.5583820343018,10.4684820175171,10.4193504333496,10.2725051879883,10.2877235412598,10.1651538848877,10.1258569717407,10.0504779815674,9.98373355865479,9.93479290008545,9.88073444366455,9.86981983184814,9.72503490447998,9.75438404083252,9.65129661560059,9.57433567047119,9.61691741943359,9.49565200805664,9.50472660064697,9.40148029327393,9.37306652069092,9.37006206512451,9.23851337432861,9.26107635498047,9.17058143615723,9.13418865203857,9.09307079315186,9.04206104278564,9.01050491333008,8.99429168701172,8.91892547607422,8.87637367248535,8.83079032897949,8.85020980834961,8.7685998916626,8.68915233612061,8.70236930847168,8.72300510406494,8.61794452667236,8.58124504089355,8.6445068359375,8.50606727600098,8.4756217956543,8.49480571746826,8.39338035583496,8.40855960845947,8.28394527435303,8.29312744140625,8.24455528259277,8.21605453491211,8.39814682006836,8.15086402893066,8.1017391204834,8.01566505432129,8.04723014831543,8.03486385345459,7.89296674728394,7.95892009735107,7.88672533035278,7.95783176422119,8.09768619537354,7.90451583862305,7.76882448196411,7.74488611221313,7.70281209945679,7.76951875686646,7.7963493347168,7.66550359725952,7.62679576873779,7.56478319168091,7.60219173431396,7.51252326965332,7.48431978225708,7.60391139984131,7.56968202590942,7.4435715675354,7.33680591583252,7.34937438964844,7.3546238899231,7.39052467346191,7.38122158050537,7.33509435653687,7.31017761230469,7.17349510192871,7.22819728851318,7.24905633926392,7.12573509216309,7.06550159454346,7.15230159759521,7.12752847671509,7.02451620101929,7.0416449546814,7.11582126617432,7.0580961227417,7.0879448890686,6.96181125640869,6.91343383789062,6.90550518035889,6.92163362503052,6.97114095687866,6.88561754226685,6.88316240310669,6.84450254440308,6.85808601379395,6.84144973754883,6.67694664001465,6.76705226898193,6.82278089523315,6.70803375244141,6.68880367279053,6.74033765792847,6.65711069107056,6.78649396896362,6.71091651916504,6.6289493560791,6.62159261703491,6.59318351745605,6.59841356277466,6.5420955657959,6.63007297515869,6.61824655532837,6.51571760177612,6.4785852432251,6.46391611099243,6.52361974716186,6.57953472137451,6.44972553253174,6.44695377349854,6.49660682678223,6.55763463973999,6.42909755706787,6.37904682159424,6.36657018661499,6.34942274093628,6.3587290763855,6.34550409317017,6.35594387054443,6.37321033477783,6.42111158370972,6.30793361663818,6.52899122238159,6.38323173522949,6.28913412094116,6.22648000717163,6.22797422409058,6.26553192138672,6.27104873657227,6.19441251754761,6.26214923858643,6.26692361831665,6.25612363815308,6.25308504104614,6.16767587661743,6.15970125198364,6.20194664001465,6.17801609039307,6.10159215927124,6.08191699981689,6.17637128829956,6.17062587738037,6.1849063873291],\"type\":\"scatter\",\"name\":\"train_ppl\",\"line\":{\"color\":\"blue\",\"dash\":\"solid\"},\"x\":[0.200000004470348,0.7,1.2,1.7,2.2,2.7,3.2,3.7,4.2,4.7,5.2,5.7,6.2,6.7,7.2,7.7,8.2,8.7,9.2,9.7,10.2,10.7,11.2,11.7,12.2,12.7,13.2,13.7,14.2,14.7,15.2,15.7,16.2,16.7,17.2,17.7,18.2,18.7,19.2,19.7,20.2,20.7,21.2,21.7,22.2,22.7,23.2,23.7,24.2,24.7,25.2,25.7,26.2,26.7,27.2,27.7,28.2,28.7,29.2,29.7,30.2,30.7,31.2,31.7,32.2,32.7,33.2,33.7,34.2,34.7,35.2,35.7,36.2,36.7,37.2,37.7,38.2,38.7,39.2,39.7,40.2,40.7,41.2,41.7,42.2,42.7,43.2,43.7,44.2,44.7,45.2,45.7,46.2,46.7,47.2,47.7,48.2,48.7,49.2,49.7,50.2,50.7,51.2,51.7,52.2,52.7,53.2,53.7,54.2,54.7,55.2,55.7,56.2,56.7,57.2,57.7,58.2,58.7,59.2,59.7,60.2,60.7,61.2,61.7,62.2,62.7,63.2,63.7,64.2,64.7,65.2,65.7,66.2,66.7,67.2,67.7,68.2,68.7,69.2,69.7,70.2,70.7,71.2,71.7,72.2,72.7,73.2,73.7,74.2,74.7,75.2,75.7,76.2,76.7,77.2,77.7,78.2,78.7,79.2,79.7,80.2,80.7,81.2,81.7,82.2,82.7,83.2,83.7,84.2,84.7,85.2,85.7,86.2,86.7,87.2,87.7,88.2,88.7,89.2,89.7,90.2,90.7,91.2,91.7,92.2,92.7,93.2,93.7,94.2,94.7,95.2,95.7,96.2,96.7,97.2,97.7,98.2,98.7,99.2,99.7]},{\"name\":\"val_ppl\",\"type\":\"scatter\",\"y\":[20.9038463592529,18.7930847167969,17.7539726257324,17.0629508972168,16.6602848052979,16.2447113037109,15.6586326599121,15.3573625564575,14.5834711074829,14.2036779403687,13.2932107925415,12.7617319107056,12.2079439163208,11.6559873580933,11.3027206420898,10.9496957778931,10.6526580810547,10.520969581604,10.3189002990723,10.141382598877,10.0128095626831,9.94234085083008,9.8830810546875,9.81591033935547,9.72952709197998,9.60851669311523,9.55093402862549,9.46008281707764,9.41168460845947,9.39004325866699,9.29665870666504,9.22130165100098,9.16988697052002,9.11295661926269,9.05702152252197,8.96810474395752,8.94830913543701,8.97192630767822,8.84569759368896,8.91968841552734,8.84252262115479,8.78166637420654,8.67852783203125,8.56667070388794,8.53374738693237,8.49074783325195,8.48862981796265,8.41467800140381,8.39001913070679,8.42064142227173,8.22620010375977,8.29219074249268,8.27465591430664,8.18296756744385,8.05615453720093,8.03059864044189,7.94701833724976,7.98484230041504,7.93228273391724,7.94714374542236,7.88370389938355,7.92971935272217,7.75877285003662,7.85782890319824,7.69555797576904,7.70388517379761,7.68813276290894,7.60497360229492,7.60205192565918,7.60955591201782,7.58246870040894,7.47560911178589,7.5792293548584,7.47139101028442,7.4423397064209,7.56278924942017,7.49358072280884,7.53951768875122,7.39945707321167,7.39325189590454,7.33133859634399,7.42870540618897,7.30861301422119,7.51829833984375,7.26308994293213,7.33493909835815,7.26410474777222,7.28435659408569,7.24679203033447,7.42365608215332,7.23276195526123,7.21539850234985,7.25432910919189,7.31574668884277,7.4058892250061,7.18014373779297,7.23516712188721,7.1969687461853,7.2898196220398,7.37184362411499],\"line\":{\"color\":\"orange\",\"dash\":\"dot\"},\"x\":[0.899999988079071,1.89999997615814,2.9,3.90000004768372,4.9,5.9,6.9,7.90000009536743,8.9,9.9,10.9,11.9,12.9,13.9,14.9,15.8999998092651,16.9,17.9,18.9,19.9,20.9,21.9,22.9,23.9,24.9,25.9,26.9,27.9,28.9,29.9,30.9,31.8999996185303,32.9,33.9,34.9,35.9,36.9,37.9,38.9,39.9,40.9,41.9,42.9,43.9,44.9,45.9,46.9,47.9,48.9,49.9,50.9,51.9,52.9,53.9,54.9,55.9,56.9,57.9,58.9,59.9,60.9,61.9,62.9,63.9000007629395,64.9,65.9,66.9,67.9,68.9,69.9,70.9,71.9,72.9,73.9,74.9,75.9,76.9,77.9,78.9,79.9,80.9,81.9,82.9,83.9,84.9,85.9,86.9,87.9,88.9,89.9,90.9,91.9,92.9,93.9,94.9,95.9,96.9,97.9,98.9,99.9]}] ,{\"yaxis\":{\"type\":\"linear\"},\"title\":{\"text\":\"\"},\"width\":3.5,\"height\":2.5,\"xaxis\":{\"title\":\"epoch\",\"range\":[0,100],\"type\":\"linear\"}} );\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Warning",
     "evalue": "Argument \":\" isn't numeric in array element at reply input line 16.\n",
     "output_type": "error",
     "traceback": [
      "Argument \":\" isn't numeric in array element at reply input line 16.\n"
     ]
    }
   ],
   "source": [
    "my $data = d2l::TimeMachine->new(batch_size => 1024, num_steps => 32);\n",
    "my $rnn = RNNScratch->new(num_inputs => $data->{vocab}->len, num_hiddens => 32);\n",
    "my $model = RNNLMScratch->new(rnn => $rnn, vocab_size => $data->{vocab}->len, lr => 1);\n",
    "my $trainer = d2l::Trainer->new(max_epochs => 100, gradient_clip_val => 1, num_gpus => 1);\n",
    "$trainer->fit($model, $data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537c695",
   "metadata": {},
   "source": [
    "## 9.5.5. Descodificación\n",
    "\n",
    "Una vez que se ha aprendido un modelo de lenguaje,\n",
    "podemos usarlo no solo para predecir el siguiente token\n",
    "sino para continuar prediciendo cada uno de los siguientes,\n",
    "tratando el token previamente predicho como si\n",
    "fuera el siguiente en la entrada.\n",
    "A veces solo querremos generar texto\n",
    "como si estuviéramos comenzando al principio\n",
    "de un documento.\n",
    "Sin embargo, a menudo es útil condicionar\n",
    "el modelo de lenguaje en un prefijo proporcionado por el usuario.\n",
    "Por ejemplo, si estuviéramos desarrollando una\n",
    "función de autocompletar para un motor de búsqueda\n",
    "o para ayudar a los usuarios a escribir correos electrónicos,\n",
    "querríamos introducir lo que han \n",
    "escrito hasta ahora (el prefijo),\n",
    "y luego generar una continuación probable.\n",
    "\n",
    "\n",
    "El siguiente método `predict`\n",
    "genera una continuación, un carácter a la vez,\n",
    "después de procesar un `prefijo` proporcionado por el usuario.\n",
    "Al recorrer los caracteres en `prefijo`,\n",
    "seguimos pasando el estado oculto\n",
    "al siguiente paso de tiempo\n",
    "pero no generamos ninguna salida.\n",
    "Esto se llama el período de *calentamiento*.\n",
    "Después de procesar el prefijo, ahora estamos\n",
    "listos para comenzar a emitir los caracteres siguientes,\n",
    "cada uno de los cuales será retroalimentado al modelo\n",
    "como entrada en el siguiente paso de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "640f998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*RNNLMScratch::predict"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Subroutine RNNLMScratch::predict redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n",
     "output_type": "error",
     "traceback": [
      "Subroutine RNNLMScratch::predict redefined at /usr/local/lib/perl5/site_perl/5.32.1/x86_64-linux/d2l.pm line 4456.\n"
     ]
    }
   ],
   "source": [
    "my $predict = sub {\n",
    "    my ($self, $prefix, $num_preds, $vocab, $device) = @_;\n",
    "    \n",
    "    my ($state, @outputs) = (undef, $vocab->{$prefix->[0]});\n",
    "\n",
    "    for my $i (0..(length($prefix) + $num_preds - 1)) {\n",
    "    \n",
    "        my $X = mx->nd->array([[$outputs[-1]]], ctx => $device);\n",
    "       \n",
    "        my $embs = $self->one_hot($X);\n",
    "        \n",
    "        my ($rnn_outputs, $state) = $self->{rnn}($embs, $state);\n",
    "\n",
    "        if ($i < length($prefix) - 1) { \n",
    "        \n",
    "            #no funciona\n",
    "            #prefix solo debe ser una letra \n",
    "            print \"Value of prefix: \", ($prefix->[$i + 1]);\n",
    "            #push @outputs, $vocab->getitem($prefix->[$i + 1]);\n",
    "            last;\n",
    "            \n",
    "            \n",
    "            \n",
    "        } else {  \n",
    "        \n",
    "            my $Y = $self->output_layer($rnn_outputs);\n",
    "            print \"Value of \\$Y: \", ($Y);\n",
    "            my $index = int($Y->argmax(axis => 2)->reshape(1));\n",
    "            \n",
    "            push @outputs, $index;\n",
    "}\n",
    "\n",
    "    }\n",
    "    #no funciona\n",
    "    \n",
    "    my @tokens = map { $vocab->{idx_to_token}->[$_] // '<unk>' } @outputs;\n",
    "    \n",
    "    \n",
    "    return join('', @tokens);\n",
    "};\n",
    "\n",
    "d2l->add_to_class('RNNLMScratch', 'predict', $predict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a043d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of prefix: has"
     ]
    },
    {
     "data": {
      "text/plain": [
       " "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "Warning",
     "evalue": "Use of uninitialized value $_ in array element at reply input line 36.\n",
     "output_type": "error",
     "traceback": [
      "Use of uninitialized value $_ in array element at reply input line 36.\n"
     ]
    }
   ],
   "source": [
    " $model->predict(['it', 'has'], 20, $data->{vocab}, d2l::try_gpu());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d307d53",
   "metadata": {},
   "source": [
    "Aunque implementar el modelo RNN anterior desde cero es instructivo, no es conveniente.\n",
    "En la siguiente sección, veremos cómo aprovechar los frameworks de aprendizaje profundo para crear RNNs\n",
    "usando arquitecturas estándar y obtener mejoras en el rendimiento \n",
    "al depender de funciones de biblioteca altamente optimizadas.\n",
    "\n",
    "\n",
    "## Resumen\n",
    "\n",
    "Podemos entrenar modelos de lenguaje basados en RNN para generar texto siguiendo el prefijo de texto proporcionado por el usuario.\n",
    "Un modelo de lenguaje RNN simple consiste en codificación de entrada, modelado RNN y generación de salida.\n",
    "Durante el entrenamiento, el recorte de gradientes puede mitigar el problema de gradientes que explotan, pero no aborda el problema de gradientes que desaparecen. En el experimento, implementamos un modelo de lenguaje RNN simple y lo entrenamos con recorte de gradientes en secuencias de texto, tokenizadas a nivel de carácter. Condicionando en un prefijo, podemos usar un modelo de lenguaje para generar continuaciones probables, lo cual resulta útil en muchas aplicaciones, por ejemplo, funciones de autocompletar.\n",
    "\n",
    "\n",
    "## Ejercicios\n",
    "\n",
    "1. ¿El modelo de lenguaje implementado predice el siguiente token basado en todos los tokens pasados hasta el primer token en *La Máquina del Tiempo*?\n",
    "1. ¿Qué hiperparámetro controla la longitud de la historia utilizada para la predicción?\n",
    "1. Demuestra que la codificación one-hot es equivalente a elegir un embedding diferente para cada objeto.\n",
    "1. Ajusta los hiperparámetros (por ejemplo, número de épocas, número de unidades ocultas, número de pasos de tiempo en un minibatch y tasa de aprendizaje) para mejorar la perplejidad. ¿Hasta dónde puedes llegar manteniéndote con esta arquitectura simple?\n",
    "1. Reemplaza la codificación one-hot con embeddings aprendibles. ¿Esto conduce a un mejor rendimiento?\n",
    "1. Realiza un experimento para determinar qué tan bien este modelo de lenguaje\n",
    "   entrenado en *La Máquina del Tiempo* funciona en otros libros de H. G. Wells,\n",
    "   por ejemplo, *La Guerra de los Mundos*.\n",
    "1. Realiza otro experimento para evaluar la perplejidad de este modelo\n",
    "   en libros escritos por otros autores.\n",
    "1. Modifica el método de predicción para usar muestreo\n",
    "   en lugar de elegir el siguiente carácter más probable.\n",
    "    * ¿Qué sucede?\n",
    "    * Sesga el modelo hacia salidas más probables, por ejemplo, \n",
    "    muestreando de \\(q(x_t \\mid x_{t-1}, \\ldots, x_1) \\propto P(x_t \\mid x_{t-1}, \\ldots, x_1)^\\alpha\\) para \\(\\alpha > 1\\).\n",
    "1. Ejecuta el código de esta sección sin recortar el gradiente. ¿Qué pasa?\n",
    "1. Reemplaza la función de activación utilizada en esta sección con ReLU \n",
    "   y repite los experimentos de esta sección. ¿Todavía necesitamos recortar el gradiente? ¿Por qué?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPerl 0.011",
   "language": "perl",
   "name": "iperl"
  },
  "language_info": {
   "file_extension": ".pl",
   "mimetype": "text/x-perl",
   "name": "perl",
   "version": "5.32.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
