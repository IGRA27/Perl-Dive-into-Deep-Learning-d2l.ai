{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2236f98d",
   "metadata": {},
   "source": [
    "# 11.3. Attention Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f382b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autor: Isaac Reyes\n",
    "#Librerias:\n",
    "#use Math::Trig;\n",
    "#use AI::MXNet 'mx';\n",
    "#use AI::MXNet::Gluon::NN 'nn';\n",
    "#mx->npx->set_np();\n",
    "use strict; \n",
    "use warnings; \n",
    "use Data::Dump qw(dump); \n",
    "use d2l; \n",
    "IPerl->load_plugin('Chart::Plotly');  #cargamos para graficar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd78e8d9",
   "metadata": {},
   "source": [
    "## 11.3.1. Dot Product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cc01e",
   "metadata": {},
   "source": [
    "### 11.3.1. Dot Product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f4397",
   "metadata": {},
   "source": [
    "#### 11.3.2.1. Masked Softmax Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56214b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub masked_softmax {\n",
    "    #en el ultimo eje\n",
    "    my ($X, $valid_lens) = @_; #@save\n",
    "    #X: tensores dimensiones\n",
    "    if (!defined $valid_lens){\n",
    "        return mx->nd->softmax($X);\n",
    "    } else {\n",
    "        my $shape = $X->shape;\n",
    "        if ($valid_lens->ndim == 1){\n",
    "        $valid_lens = $valid_lens->repeat($shape->[1]);\n",
    "        } else {\n",
    "        $valid_lens = $valid_lens->reshape([-1]);\n",
    "        }\n",
    "     $X = mx->nd->SequenceMask($X->reshape([-1, $shape->[-1]]), $valid_lens, 1,\n",
    "                               value => -1e6, axis => 1 );\n",
    "     return mx->nd->softmax($X)->reshape($shape);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef90b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "#my $X_test = mx->np->random->uniform(size => [2, 2, 4]);\n",
    "#my $valid_lens_test = mx->np->array([2, 3]);\n",
    "#my $result = masked_softmax($X_test, $valid_lens_test);\n",
    "#print $result->aspdl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b48019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[\n",
       " [\n",
       "  [       1        0        0        0]\n",
       "  [0.358484 0.365888 0.275628        0]\n",
       " ]\n",
       " [\n",
       "  [0.543703 0.456297        0        0]\n",
       "  [0.195988 0.255804 0.199167 0.349041]\n",
       " ]\n",
       "]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_softmax(mx->nd->random->uniform(shape => [2, 2, 4]), mx->nd->array([2, 3]))->aspdl;\n",
    "masked_softmax(mx->nd->random->uniform(shape => [2, 2, 4]), mx->nd->array([[1, 3], [2, 4]]))->aspdl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14892790",
   "metadata": {},
   "source": [
    "##### 11.3.2.2. Batch Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13a89e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $Q = mx->nd->ones([2, 3, 4]);\n",
    "my $K = mx->nd->ones([2, 4, 6]);\n",
    "d2l->check_shape(mx->nd->batch_dot($Q, $K), [2, 3, 6]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac9173",
   "metadata": {},
   "source": [
    "##### 11.3.3. Scaled Dot Product Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b96036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package DotProductAttention{\n",
    "  use base qw(AI::MXNet::Gluon::Block); #@save\n",
    "  sub new {\n",
    "    my ($class, %args) = (shift, d2l->get_arguments(dropout => undef, \\@_));\n",
    "    my  $self = $class->SUPER::new();     \n",
    "    $self->{dropout} = mx->gluon->nn->Dropout($args{dropout});\n",
    "    map {$self->register_child($self->{$_})} ('dropout');\n",
    "\n",
    "    return bless ($self, $class);\n",
    "    #tamaÃ±os formas de queries y todo\n",
    " }\n",
    " sub masked_softmax{\n",
    "    my ($self, $X, $valid_lens) = @_; #@save\n",
    "    #X tensor \n",
    "    if (!defined $valid_lens){\n",
    "        return mx->nd->softmax($X);\n",
    "    } else {\n",
    "        my $shape = $X->shape;\n",
    "        if ($valid_lens->ndim == 1){\n",
    "        $valid_lens = $valid_lens->repeat($shape->[1]);\n",
    "        } else {\n",
    "        $valid_lens = $valid_lens->reshape([-1]);\n",
    "        }\n",
    "     $X = mx->nd->SequenceMask($X->reshape([-1, $shape->[-1]]), $valid_lens, 1, value => -1e6, axis => 1 );\n",
    "     return mx->nd->softmax($X)->reshape($shape);\n",
    "    }\n",
    " }\n",
    "sub forward {\n",
    "    my ($self, $queries, $keys, $values, $valid_lens) = @_;\n",
    "    my $d = $queries->shape->[-1];\n",
    "    my $scores = mx->nd->batch_dot($queries, $keys, transpose_b => 1) / sqrt($d);\n",
    "    $self->{attention_weights} = $self->masked_softmax($scores, $valid_lens);\n",
    "    return mx->nd->batch_dot($self->{dropout}($self->{attention_weights}), $values);\n",
    "}  \n",
    "1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2212a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $queries = mx->nd->random->normal(0, 1, shape=>[2, 1, 2]);\n",
    "my $keys = mx->nd->random->normal(0, 1, shape=>[2, 10, 2]);\n",
    "my $values = mx->nd->random->normal(0, 1, shape=>[2, 10, 4]);\n",
    "my $valid_lens = mx->nd->array([2,6]);\n",
    "my $attention = DotProductAttention->new(dropout=> 0.5);\n",
    "$attention->initialize();\n",
    "d2l->check_shape($attention->($queries, $keys, $values, $valid_lens), [2, 1, 4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba2a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "//# sourceURL=iperl-devel-plugin-chart-plotly.js\n",
       "            $('#Plotly').each(function(i, e) { $(e).attr('id', 'plotly') });\n",
       "\n",
       "            if (!window.Plotly) {\n",
       "                requirejs.config({\n",
       "                  paths: {\n",
       "                    plotly: ['https://cdn.plot.ly/plotly-latest.min']},\n",
       "                });\n",
       "                window.Plotly = {\n",
       "react : function (div, data, layout, config){\n",
       "                    require(['plotly'], function(plotly) {\n",
       "                      window.Plotly=plotly;\n",
       "Plotly.react(div, data, layout, config);                    });\n",
       "                  }\n",
       "                }\n",
       "            }\n",
       "</script>\n",
       "<div id=\"986b2ac8-b8b8-11ee-9e2d-d2cbcd3da0a9\"></div>\n",
       "\n",
       "<script>\n",
       "Plotly.react(document.getElementById('986b2ac8-b8b8-11ee-9e2d-d2cbcd3da0a9'),[{\"colorscale\":\"RdBu\",\"type\":\"heatmap\",\"yaxis\":\"y1\",\"z\":[[0.158712089061737,0.0747283771634102,0.308351159095764,0.168998286128044,0.107391826808453,0.181818246841431,0,0,0,0],[0.526034891605377,0.473965167999268,0,0,0,0,0,0,0,0]],\"colorbar\":{\"len\":0.6},\"showlegend\":false,\"xaxis\":\"x1\"}] ,{\"width\":600,\"height\":600,\"xaxis\":{\"domain\":[0,1],\"title\":\"Keys\",\"anchor\":\"y1\"},\"title\":{\"text\":\"\"},\"yaxis\":{\"anchor\":\"x1\",\"title\":\"Queries\",\"domain\":[0,1]}} );\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my $attention_weights = $attention->{attention_weights}->reshape([1, 1, 2, 10]);\n",
    "d2l->show_heatmaps($attention_weights, xlabel => 'Keys', ylabel => 'Queries');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393a181",
   "metadata": {},
   "source": [
    "## 11.3.4. Additive Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234a4714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package AdditiveAttention{\n",
    "  use base qw(AI::MXNet::Gluon::Block); #@save\n",
    "  sub new {\n",
    "    my ($class, %args) = (shift, d2l->get_arguments(num_hiddens => undef ,dropout => undef, \\@_));\n",
    "    my  $self = $class->SUPER::new(%args); \n",
    "    #Aplanamos con flatten\n",
    "    $self->{W_k} = mx->gluon->nn->Dense($args{num_hiddens}, use_bias => 0, flatten => 0);\n",
    "    $self->{W_q} = mx->gluon->nn->Dense($args{num_hiddens}, use_bias => 0, flatten => 0);\n",
    "    $self->{w_v} = mx->gluon->nn->Dense(1, use_bias=> 0, flatten => 0);\n",
    "    $self->{dropout} = mx->gluon->nn->Dropout($args{dropout});\n",
    "    map {$self->register_child($self->{$_})} ('W_k', 'W_q', 'w_v','dropout'); \n",
    "    return bless ($self, $class);\n",
    " }\n",
    "  sub masked_softmax{\n",
    "    my ($self, $X, $valid_lens) = @_; #@save\n",
    "    #X tensores\n",
    "    if (!defined $valid_lens){\n",
    "        return mx->nd->softmax($X);\n",
    "    } else {\n",
    "        my $shape = $X->shape;\n",
    "        if ($valid_lens->ndim == 1){\n",
    "        $valid_lens = $valid_lens->repeat($shape->[1]);\n",
    "        } else {\n",
    "        $valid_lens = $valid_lens->reshape([-1]);\n",
    "        }\n",
    "     # On the last axis, replace masked elements with a very large negative\n",
    "     # value, whose exponentiation outputs 0\n",
    "     $X = mx->nd->SequenceMask($X->reshape([-1, $shape->[-1]]), $valid_lens, 1, value => -1e6, axis => 1 );\n",
    "     return mx->nd->softmax($X)->reshape($shape);\n",
    "    }\n",
    " }\n",
    " \n",
    "  sub forward{\n",
    "      my ($self, $queries, $keys, $values, $valid_lens) = @_;\n",
    "       ($queries, $keys) = ($self->{W_q}->forward($queries), $self->{W_k}->forward($keys));\n",
    "        # After dimension expansion, shape of queries: (batch_size, no. of\n",
    "        # queries, 1, num_hiddens) and shape of keys: (batch_size, 1,\n",
    "        # no. of key-value pairs, num_hiddens). Sum them up with\n",
    "        # broadcasting\n",
    "        my $features = mx->nd->expand_dims($queries, axis => 2) + mx->nd->expand_dims($keys, axis => 1);\n",
    "        $features = mx->nd->tanh($features);  \n",
    "        # There is only one output of self.w_v, so we remove the last\n",
    "        # one-dimensional entry from the shape. Shape of scores:\n",
    "        # (batch_size, no. of queries, no. of key-value pairs)\n",
    "        my $scores = mx->nd->squeeze($self->{w_v}->forward($features), axis => -1);\n",
    "        $self->{attention_weights} = $self->masked_softmax($scores, $valid_lens);\n",
    "        # Shape of values: (batch_size, no. of key-value pairs, value\n",
    "        # dimension)\n",
    "        return mx->nd->batch_dot($self->{dropout}->forward($self->{attention_weights}), $values);\n",
    "   }   \n",
    "1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a154d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $queries = mx->nd->random->normal(0, 1, shape=>[2, 1, 20]);\n",
    "my $attention = AdditiveAttention->new(num_hiddens => 8, dropout => 0.1 );\n",
    "$attention->initialize();\n",
    "d2l->check_shape($attention->($queries, $keys, $values, $valid_lens), [2, 1, 4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ebf5d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "//# sourceURL=iperl-devel-plugin-chart-plotly.js\n",
       "            $('#Plotly').each(function(i, e) { $(e).attr('id', 'plotly') });\n",
       "\n",
       "            if (!window.Plotly) {\n",
       "                requirejs.config({\n",
       "                  paths: {\n",
       "                    plotly: ['https://cdn.plot.ly/plotly-latest.min']},\n",
       "                });\n",
       "                window.Plotly = {\n",
       "react : function (div, data, layout, config){\n",
       "                    require(['plotly'], function(plotly) {\n",
       "                      window.Plotly=plotly;\n",
       "Plotly.react(div, data, layout, config);                    });\n",
       "                  }\n",
       "                }\n",
       "            }\n",
       "</script>\n",
       "<div id=\"987fbac4-b8b8-11ee-9e2d-9367fcf06dda\"></div>\n",
       "\n",
       "<script>\n",
       "Plotly.react(document.getElementById('987fbac4-b8b8-11ee-9e2d-9367fcf06dda'),[{\"showlegend\":false,\"xaxis\":\"x1\",\"yaxis\":\"y1\",\"type\":\"heatmap\",\"colorscale\":\"Bluered\",\"z\":[[0.16669400036335,0.166986837983131,0.166243761777878,0.166504487395287,0.16671946644783,0.166851371526718,0,0,0,0],[0.500060260295868,0.499939799308777,0,0,0,0,0,0,0,0]],\"colorbar\":{\"len\":0.6}}] ,{\"title\":{\"text\":\"\"},\"yaxis\":{\"domain\":[0,1],\"anchor\":\"x1\",\"title\":\"Queries\"},\"width\":600,\"xaxis\":{\"domain\":[0,1],\"anchor\":\"y1\",\"title\":\"Keys\"},\"height\":600} );\n",
       "</script>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my $attention_weights = $attention->{attention_weights}->reshape([1, 1, 2, 10]);\n",
    "d2l->show_heatmaps($attention_weights, xlabel => 'Keys', ylabel => 'Queries');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb7c3076",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Bareword \"ERRORES\" not allowed while \"strict subs\" in use at reply input line 1.\n\n",
     "output_type": "error",
     "traceback": [
      "Bareword \"ERRORES\" not allowed while \"strict subs\" in use at reply input line 1.\n\n"
     ]
    }
   ],
   "source": [
    "#CORREGIR ERRORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210e31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPerl 0.011",
   "language": "perl",
   "name": "iperl"
  },
  "language_info": {
   "file_extension": ".pl",
   "mimetype": "text/x-perl",
   "name": "perl",
   "version": "5.32.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
